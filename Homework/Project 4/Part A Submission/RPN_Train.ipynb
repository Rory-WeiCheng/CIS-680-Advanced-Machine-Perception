{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from rpn import RPNHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataset and dataloader for both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the dataset ##\n",
    "imgs_path = './data/hw3_mycocodata_img_comp_zlib.h5'\n",
    "masks_path = './data/hw3_mycocodata_mask_comp_zlib.h5'\n",
    "labels_path = './data/hw3_mycocodata_labels_comp_zlib.npy'\n",
    "bboxes_path = './data/hw3_mycocodata_bboxes_comp_zlib.npy'\n",
    "paths = [imgs_path, masks_path, labels_path, bboxes_path]\n",
    "dataset = BuildDataset(paths)\n",
    "# Split the whole dataset into 80% training and 20% validation\n",
    "full_size = len(dataset)\n",
    "train_size = int(full_size * 0.8)\n",
    "val_size = full_size - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "## Build dataloader from training and validation dataset ##\n",
    "batch_size = 4\n",
    "train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "train_loader = train_build_loader.loader()\n",
    "val_build_loader = BuildDataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "val_loader = val_build_loader.loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_top_k=2,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"best-val-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "trainer = Trainer(gpus=1, max_epochs=70, callbacks=[checkpoint_callback])\n",
    "rpn_net = RPNHead().cuda()\n",
    "trainer.fit(rpn_net, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "train_loss = np.array(rpn_net.total_loss)\n",
    "cls_loss = np.array(rpn_net.cls_loss)\n",
    "reg_loss = np.array(rpn_net.reg_loss)\n",
    "val_loss = np.array(rpn_net.val_loss)\n",
    "np.save(\"total_loss.npy\", train_loss)\n",
    "np.save(\"cls_loss.npy\", cls_loss)\n",
    "np.save( \"reg_loss.npy\", reg_loss)\n",
    "np.save(\"val_loss.npy\", val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8940013284a1b229d803e2b39c8affb19055b93de71980f73f46f3bc3f114b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
